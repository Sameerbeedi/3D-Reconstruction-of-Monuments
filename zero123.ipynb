{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a71475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.1.0\n",
      "Uninstalling torch-2.1.0:\n",
      "  Successfully uninstalled torch-2.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to remove contents in a temporary directory 'D:\\college\\imp-doc\\sem6\\GENAI\\project\\.venv\\Lib\\site-packages\\~orch'.\n",
      "You can safely remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp39-cp39-win_amd64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: torchvision in d:\\college\\imp-doc\\sem6\\genai\\project\\.venv\\lib\\site-packages (0.16.0)\n",
      "Requirement already satisfied: torchaudio in d:\\college\\imp-doc\\sem6\\genai\\project\\.venv\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: filelock in d:\\college\\imp-doc\\sem6\\genai\\project\\.venv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\college\\imp-doc\\sem6\\genai\\project\\.venv\\lib\\site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: networkx in d:\\college\\imp-doc\\sem6\\genai\\project\\.venv\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in d:\\college\\imp-doc\\sem6\\genai\\project\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in d:\\college\\imp-doc\\sem6\\genai\\project\\.venv\\lib\\site-packages (from torch) (2023.6.0)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\college\\imp-doc\\sem6\\genai\\project\\.venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in d:\\college\\imp-doc\\sem6\\genai\\project\\.venv\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: requests in d:\\college\\imp-doc\\sem6\\genai\\project\\.venv\\lib\\site-packages (from torchvision) (2.32.3)\n",
      "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp39-cp39-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\college\\imp-doc\\sem6\\genai\\project\\.venv\\lib\\site-packages (from torchvision) (9.5.0)\n",
      "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchaudio\n",
      "  Using cached https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp39-cp39-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\college\\imp-doc\\sem6\\genai\\project\\.venv\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Using cached https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp39-cp39-win_amd64.whl (2532.2 MB)\n",
      "Using cached https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp39-cp39-win_amd64.whl (6.1 MB)\n",
      "Using cached https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp39-cp39-win_amd64.whl (4.2 MB)\n",
      "Installing collected packages: sympy, torch, torchvision, torchaudio\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.3\n",
      "    Uninstalling sympy-1.13.3:\n",
      "      Successfully uninstalled sympy-1.13.3\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.16.0\n",
      "    Uninstalling torchvision-0.16.0:\n",
      "      Successfully uninstalled torchvision-0.16.0\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 2.1.0\n",
      "    Uninstalling torchaudio-2.1.0:\n",
      "      Successfully uninstalled torchaudio-2.1.0\n",
      "Successfully installed sympy-1.13.1 torch-2.6.0+cu124 torchaudio-2.6.0+cu124 torchvision-0.21.0+cu124\n"
     ]
    }
   ],
   "source": [
    "# !pip uninstall torch -y\n",
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
    "\n",
    " #Zero123 uses ControlNet and Stable Diffusion  generate images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3044c859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.6.0+cu124'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdfd395e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install diffusers==0.20.2 transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ff41397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: diffusers in d:\\college\\imp-doc\\sem6\\genai\\project\\.venv\\lib\\site-packages (0.20.2)\n",
      "Collecting diffusers\n",
      "  Using cached diffusers-0.33.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: importlib-metadata in d:\\college\\imp-doc\\sem6\\genai\\project\\.venv\\lib\\site-packages (from diffusers) (8.6.1)\n",
      "Requirement already satisfied: filelock in d:\\college\\imp-doc\\sem6\\genai\\project\\.venv\\lib\\site-packages (from diffusers) (3.13.1)\n",
      "Collecting huggingface-hub>=0.27.0 (from diffusers)\n",
      "  Using cached huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy in d:\\college\\imp-doc\\sem6\\genai\\project\\.venv\\lib\\site-packages (from diffusers) (1.26.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\college\\imp-doc\\sem6\\genai\\project\\.venv\\lib\\site-packages (from diffusers) (2024.11.6)\n",
      "Requirement already satisfied: requests in d:\\college\\imp-doc\\sem6\\genai\\project\\.venv\\lib\\site-packages (from diffusers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in d:\\college\\imp-doc\\sem6\\genai\\project\\.venv\\lib\\site-packages (from diffusers) (0.5.3)\n",
      "Requirement already satisfied: Pillow in d:\\college\\imp-doc\\sem6\\genai\\project\\.venv\\lib\\site-packages (from diffusers) (11.0.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\college\\imp-doc\\sem6\\genai\\project\\.venv\\lib\\site-packages (from huggingface-hub>=0.27.0->diffusers) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\college\\imp-doc\\sem6\\genai\\project\\.venv\\lib\\site-packages (from huggingface-hub>=0.27.0->diffusers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\college\\imp-doc\\sem6\\genai\\project\\.venv\\lib\\site-packages (from huggingface-hub>=0.27.0->diffusers) (6.0.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in d:\\college\\imp-doc\\sem6\\genai\\project\\.venv\\lib\\site-packages (from huggingface-hub>=0.27.0->diffusers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\college\\imp-doc\\sem6\\genai\\project\\.venv\\lib\\site-packages (from huggingface-hub>=0.27.0->diffusers) (4.13.2)\n",
      "Requirement already satisfied: zipp>=3.20 in d:\\college\\imp-doc\\sem6\\genai\\project\\.venv\\lib\\site-packages (from importlib-metadata->diffusers) (3.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\college\\imp-doc\\sem6\\genai\\project\\.venv\\lib\\site-packages (from requests->diffusers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\college\\imp-doc\\sem6\\genai\\project\\.venv\\lib\\site-packages (from requests->diffusers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\college\\imp-doc\\sem6\\genai\\project\\.venv\\lib\\site-packages (from requests->diffusers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\college\\imp-doc\\sem6\\genai\\project\\.venv\\lib\\site-packages (from requests->diffusers) (2025.1.31)\n",
      "Requirement already satisfied: colorama in d:\\college\\imp-doc\\sem6\\genai\\project\\.venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.27.0->diffusers) (0.4.6)\n",
      "Using cached diffusers-0.33.1-py3-none-any.whl (3.6 MB)\n",
      "Using cached huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Installing collected packages: huggingface-hub, diffusers\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.15.1\n",
      "    Uninstalling huggingface-hub-0.15.1:\n",
      "      Successfully uninstalled huggingface-hub-0.15.1\n",
      "  Attempting uninstall: diffusers\n",
      "    Found existing installation: diffusers 0.20.2\n",
      "    Uninstalling diffusers-0.20.2:\n",
      "      Successfully uninstalled diffusers-0.20.2\n",
      "Successfully installed diffusers-0.33.1 huggingface-hub-0.30.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-huggingface 0.1.2 requires tokenizers>=0.19.1, but you have tokenizers 0.13.3 which is incompatible.\n",
      "langchain-huggingface 0.1.2 requires transformers>=4.39.0, but you have transformers 4.30.0 which is incompatible.\n",
      "sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.30.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# !pip uninstall diffusers -y\n",
    "# !pip uninstall transformers -y\n",
    "# !pip uninstall huggingface_hub -y\n",
    "# !pip install diffusers==0.20.2\n",
    "# !pip install transformers==4.30.0\n",
    "# !pip install huggingface_hub==0.15.1\n",
    "!pip install diffusers --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffe725ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\college\\imp-doc\\sem6\\GENAI\\project\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n",
      "Loading pipeline components...:  62%|██████▎   | 5/8 [00:01<00:01,  2.87it/s]An error occurred while trying to fetch C:\\Users\\sameer\\.cache\\huggingface\\hub\\models--sudo-ai--zero123plus-v1.1\\snapshots\\36df7de980afd15f80b2e1a4e9a920d7020e2654\\vae: Error no file named diffusion_pytorch_model.safetensors found in directory C:\\Users\\sameer\\.cache\\huggingface\\hub\\models--sudo-ai--zero123plus-v1.1\\snapshots\\36df7de980afd15f80b2e1a4e9a920d7020e2654\\vae.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
      "Loading pipeline components...:  88%|████████▊ | 7/8 [00:01<00:00,  4.59it/s]An error occurred while trying to fetch C:\\Users\\sameer\\.cache\\huggingface\\hub\\models--sudo-ai--zero123plus-v1.1\\snapshots\\36df7de980afd15f80b2e1a4e9a920d7020e2654\\unet: Error no file named diffusion_pytorch_model.safetensors found in directory C:\\Users\\sameer\\.cache\\huggingface\\hub\\models--sudo-ai--zero123plus-v1.1\\snapshots\\36df7de980afd15f80b2e1a4e9a920d7020e2654\\unet.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
      "Loading pipeline components...: 100%|██████████| 8/8 [00:02<00:00,  3.98it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Zero123PlusPipeline {\n",
       "  \"_class_name\": \"Zero123PlusPipeline\",\n",
       "  \"_diffusers_version\": \"0.33.1\",\n",
       "  \"_name_or_path\": \"sudo-ai/zero123plus-v1.1\",\n",
       "  \"feature_extractor_clip\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPImageProcessor\"\n",
       "  ],\n",
       "  \"feature_extractor_vae\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPImageProcessor\"\n",
       "  ],\n",
       "  \"ramping_coefficients\": [\n",
       "    0.0,\n",
       "    0.2060057818889618,\n",
       "    0.18684479594230652,\n",
       "    0.24342191219329834,\n",
       "    0.18507817387580872,\n",
       "    0.1703828126192093,\n",
       "    0.15628913044929504,\n",
       "    0.14174538850784302,\n",
       "    0.13617539405822754,\n",
       "    0.13569170236587524,\n",
       "    0.1269884556531906,\n",
       "    0.1200924888253212,\n",
       "    0.12816639244556427,\n",
       "    0.13058121502399445,\n",
       "    0.14201879501342773,\n",
       "    0.15004529058933258,\n",
       "    0.1620427817106247,\n",
       "    0.17207716405391693,\n",
       "    0.18534132838249207,\n",
       "    0.20002241432666779,\n",
       "    0.21657466888427734,\n",
       "    0.22996725142002106,\n",
       "    0.24613411724567413,\n",
       "    0.25141021609306335,\n",
       "    0.26613450050354004,\n",
       "    0.271847128868103,\n",
       "    0.2850190997123718,\n",
       "    0.285749226808548,\n",
       "    0.2813953757286072,\n",
       "    0.29509517550468445,\n",
       "    0.30109965801239014,\n",
       "    0.31370124220848083,\n",
       "    0.3134534955024719,\n",
       "    0.3108579218387604,\n",
       "    0.32147032022476196,\n",
       "    0.33548328280448914,\n",
       "    0.3301997184753418,\n",
       "    0.3254660964012146,\n",
       "    0.3514464199542999,\n",
       "    0.35993096232414246,\n",
       "    0.3510829508304596,\n",
       "    0.37661612033843994,\n",
       "    0.3913513123989105,\n",
       "    0.42122599482536316,\n",
       "    0.3954688012599945,\n",
       "    0.4260983467102051,\n",
       "    0.479139506816864,\n",
       "    0.4588979482650757,\n",
       "    0.4873477816581726,\n",
       "    0.5095643401145935,\n",
       "    0.5133851170539856,\n",
       "    0.520708441734314,\n",
       "    0.5363377928733826,\n",
       "    0.5661528706550598,\n",
       "    0.5859065651893616,\n",
       "    0.6207258701324463,\n",
       "    0.6560986638069153,\n",
       "    0.6379964351654053,\n",
       "    0.6777164340019226,\n",
       "    0.6589891910552979,\n",
       "    0.7574057579040527,\n",
       "    0.7446827292442322,\n",
       "    0.7695522308349609,\n",
       "    0.8163619041442871,\n",
       "    0.9502472281455994,\n",
       "    0.9918442368507385,\n",
       "    0.9398387670516968,\n",
       "    1.005432367324829,\n",
       "    0.9295969605445862,\n",
       "    0.9899859428405762,\n",
       "    1.044832706451416,\n",
       "    1.0427014827728271,\n",
       "    1.0829696655273438,\n",
       "    1.0062562227249146,\n",
       "    1.0966323614120483,\n",
       "    1.0550328493118286,\n",
       "    1.2108079195022583\n",
       "  ],\n",
       "  \"safety_checker\": [\n",
       "    null,\n",
       "    null\n",
       "  ],\n",
       "  \"scheduler\": [\n",
       "    \"diffusers\",\n",
       "    \"EulerAncestralDiscreteScheduler\"\n",
       "  ],\n",
       "  \"text_encoder\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTextModel\"\n",
       "  ],\n",
       "  \"tokenizer\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTokenizer\"\n",
       "  ],\n",
       "  \"unet\": [\n",
       "    \"diffusers\",\n",
       "    \"UNet2DConditionModel\"\n",
       "  ],\n",
       "  \"vae\": [\n",
       "    \"diffusers\",\n",
       "    \"AutoencoderKL\"\n",
       "  ],\n",
       "  \"vision_encoder\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPVisionModelWithProjection\"\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip uninstall diffusers transformers huggingface_hub -y\n",
    "# !pip install diffusers==0.20.2 transformers==4.30.0 huggingface_hub==0.15.1\n",
    "# !pip install --upgrade diffusers\n",
    "# !pip install --upgrade transformers\n",
    "# !pip install --upgrade huggingface_hub\n",
    "\n",
    "import torch\n",
    "import requests\n",
    "from PIL import Image\n",
    "from huggingface_hub import hf_hub_download\n",
    "from diffusers import DiffusionPipeline, EulerAncestralDiscreteScheduler\n",
    "\n",
    "# Load the pipeline\n",
    "pipeline = DiffusionPipeline.from_pretrained(\n",
    "    \"sudo-ai/zero123plus-v1.1\", custom_pipeline=\"sudo-ai/zero123plus-pipeline\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# Feel free to tune the scheduler!\n",
    "# `timestep_spacing` parameter is not supported in older versions of `diffusers`\n",
    "# so there may be performance degradations\n",
    "# We recommend using `diffusers==0.20.2`\n",
    "pipeline.scheduler = EulerAncestralDiscreteScheduler.from_config(\n",
    "    pipeline.scheduler.config, timestep_spacing='trailing'\n",
    ")\n",
    "pipeline.to('cuda:0')\n",
    "\n",
    "#First, let's find where the custom pipeline is downloaded\n",
    "# import os\n",
    "# from huggingface_hub import hf_hub_download\n",
    "\n",
    "# pipeline_path = hf_hub_download(repo_id=\"sudo-ai/zero123plus-pipeline\", filename=\"pipeline.py\")\n",
    "# print(f\"Custom pipeline is at: {pipeline_path}\")\n",
    "\n",
    "# # You can then examine the file to see if it uses cached_download\n",
    "# with open(pipeline_path, 'r') as f:\n",
    "#     content = f.read()\n",
    "#     if 'cached_download' in content:\n",
    "#         print(\"Found cached_download in the pipeline file!\")\n",
    "\n",
    "# import torch\n",
    "# import diffusers\n",
    "# from diffusers import DiffusionPipeline\n",
    "\n",
    "# # Load without using custom pipeline first\n",
    "# pipeline = DiffusionPipeline.from_pretrained(\n",
    "#     \"sudo-ai/zero123plus-v1.1\",\n",
    "#     torch_dtype=torch.float16\n",
    "# )\n",
    "# pipeline = pipeline.to(\"cuda\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e3abff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:35<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1 saved as context\\output_20250424_024700_0.png\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Path to the input image\n",
    "input_image_path = \"D:\\\\college\\\\imp-doc\\\\sem6\\\\GENAI\\\\project\\\\3D-Reconstruction-of-Monuments\\\\1052-removebg-preview.png\"\n",
    "\n",
    "# Load the image\n",
    "cond = Image.open(input_image_path)\n",
    "\n",
    "# Extract the directory where the input image is stored\n",
    "context_dir = \"context\"\n",
    "\n",
    "# Number of images to generate\n",
    "num_images = 1\n",
    "\n",
    "# Generate and save images in the same directory\n",
    "for i in range(num_images):\n",
    "    result = pipeline(cond, num_inference_steps=100).images[0]\n",
    "    \n",
    "    # Optional: show the result\n",
    "    result.show()\n",
    "\n",
    "    # Create a unique filename\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_filename = f\"output_{timestamp}_{i}.png\"\n",
    "    output_path = os.path.join(context_dir, output_filename)\n",
    "\n",
    "    # Save the result\n",
    "    result.save(output_path)\n",
    "    print(f\"Image {i + 1} saved as {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
