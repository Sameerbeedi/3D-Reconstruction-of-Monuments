{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50c7a47ba83b499bad4b269d96b2d33e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler\n",
    "from controlnet_aux import MidasDetector\n",
    "import torch\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load ControlNet Depth Model\n",
    "controlnet = ControlNetModel.from_pretrained(\n",
    "    \"lllyasviel/sd-controlnet-depth\",\n",
    "    torch_dtype=torch.float16 if device==\"cuda\" else torch.float32\n",
    ")\n",
    "\n",
    "# Load Stable Diffusion Pipeline\n",
    "pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\",\n",
    "    controlnet=controlnet,\n",
    "    torch_dtype=torch.float16 if device==\"cuda\" else torch.float32\n",
    ").to(device)\n",
    "\n",
    "pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "# Load Midas Depth Estimator\n",
    "depth_estimator = MidasDetector.from_pretrained(\"lllyasviel/ControlNet\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images saved to: context\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Load the original image\n",
    "image_path = \"output_20250423_194637.png\"  # Change to your file path\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"context\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Set grid size\n",
    "rows, cols = 2, 3\n",
    "width, height = image.size\n",
    "cell_width = width // cols\n",
    "cell_height = height // rows\n",
    "\n",
    "# Split image and save\n",
    "for row in range(rows):\n",
    "    for col in range(cols):\n",
    "        left = col * cell_width\n",
    "        upper = row * cell_height\n",
    "        right = left + cell_width\n",
    "        lower = upper + cell_height\n",
    "        cropped = image.crop((left, upper, right, lower))\n",
    "        cropped.save(os.path.join(output_dir, f\"nandi_angle_{row*cols + col + 1}.png\"))\n",
    "\n",
    "print(\"Images saved to:\", output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5da95081db004d4f8222f21a745c3e14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:49<04:06, 49.35s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0b4653001e84b94b4db97fcfae97a8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [01:29<02:56, 44.17s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ed3cb6641e94da585863b5ab2cef991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [02:55<03:09, 63.23s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "711e535716e54e26ac8e3c6056e33c1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [03:31<01:44, 52.27s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0867d13c4154b318def9b09fe96f316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [04:25<00:53, 53.05s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6c1ec1ddeac424d9f84b9b954a3ae07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [04:57<00:00, 49.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Check the output_images folder.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_folder = \"D:\\\\college\\\\imp-doc\\\\sem6\\\\GENAI\\\\project\\\\3D-Reconstruction-of-Monuments\\\\context\"\n",
    "output_folder = \"output_images\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Process all images\n",
    "for filename in tqdm(os.listdir(input_folder)):\n",
    "    if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
    "        image_path = os.path.join(input_folder, filename)\n",
    "        input_image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        # Generate Depth Map\n",
    "        depth_map = depth_estimator(input_image)\n",
    "        depth_map = depth_map.resize(input_image.size)\n",
    "\n",
    "        # Prompt for generation\n",
    "        prompt = \"highly detailed, same object but from a different angle, different perspective, realistic DSLR photo\"\n",
    "\n",
    "        # Generate new view\n",
    "        output = pipe(prompt=prompt, image=depth_map, num_inference_steps=30).images[0]\n",
    "\n",
    "        # Save Outputs\n",
    "        output.save(os.path.join(output_folder, f\"output_{filename}\"))\n",
    "        depth_map.save(os.path.join(output_folder, f\"depth_{filename}\"))\n",
    "\n",
    "print(\"Done! Check the output_images folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added output_nandi_angle_1.png, total points so far: 98622\n",
      "Added output_nandi_angle_2.png, total points so far: 197037\n",
      "Added output_nandi_angle_3.png, total points so far: 294979\n",
      "Added output_nandi_angle_4.png, total points so far: 382966\n",
      "Added output_nandi_angle_5.png, total points so far: 480132\n",
      "Added output_nandi_angle_6.png, total points so far: 571800\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "# Path to your output_images directory\n",
    "input_folder = \"D:\\\\college\\\\imp-doc\\\\sem6\\\\GENAI\\\\project\\\\3D-Reconstruction-of-Monuments\\\\output_images\"\n",
    "\n",
    "# Camera intrinsics\n",
    "fx, fy = 615.426, 615.426\n",
    "cx, cy = 312.500, 249.500\n",
    "depth_scale = 5.0 / 254  # adjust if using mm, etc.\n",
    "\n",
    "# Initialize a global point cloud\n",
    "global_pcd = o3d.geometry.PointCloud()\n",
    "\n",
    "# Iterate over all depth image files\n",
    "for filename in sorted(os.listdir(input_folder)):\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg')) and \"output\" in filename:\n",
    "        image_path = os.path.join(input_folder, filename)\n",
    "        depth = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "        if depth is None:\n",
    "            print(f\"Error loading {filename}\")\n",
    "            continue\n",
    "\n",
    "        if len(depth.shape) == 3:\n",
    "            depth = cv2.cvtColor(depth, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        depth = cv2.bilateralFilter(depth, d=5, sigmaColor=75, sigmaSpace=75)\n",
    "\n",
    "        points = []\n",
    "        height, width = depth.shape\n",
    "\n",
    "        for v in range(height):\n",
    "            for u in range(width):\n",
    "                d = depth[v, u]\n",
    "                Z = d * depth_scale\n",
    "                if Z < 0.1 or Z > 5.0:\n",
    "                    continue\n",
    "                X = (u - cx) * Z / fx\n",
    "                Y = (v - cy) * Z / fy\n",
    "                points.append([X, Y, Z])\n",
    "\n",
    "        # Convert to Open3D point cloud\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        pcd.points = o3d.utility.Vector3dVector(np.array(points))\n",
    "\n",
    "        # Transform this cloud to simulate different camera angles\n",
    "        # In real scenarios, you'd get these from camera extrinsics\n",
    "        # For demo, simulate a rotating camera (example rotation)\n",
    "        angle_rad = np.radians(10 * len(global_pcd.points) // 100000)  # example increment\n",
    "        R = pcd.get_rotation_matrix_from_xyz((0, angle_rad, 0))\n",
    "        pcd.rotate(R, center=(0, 0, 0))  # Simulate motion by rotating each point cloud\n",
    "\n",
    "        # Merge with the global point cloud\n",
    "        global_pcd += pcd\n",
    "\n",
    "        print(f\"Added {filename}, total points so far: {len(global_pcd.points)}\")\n",
    "\n",
    "# Clean the merged point cloud\n",
    "global_pcd = global_pcd.voxel_down_sample(voxel_size=0.005)\n",
    "global_pcd, _ = global_pcd.remove_statistical_outlier(nb_neighbors=20, std_ratio=2.0)\n",
    "\n",
    "# Visualize the full 3D reconstruction\n",
    "o3d.visualization.draw_geometries([global_pcd])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
