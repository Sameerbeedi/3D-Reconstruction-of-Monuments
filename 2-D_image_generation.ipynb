{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.utils as vutils\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "def load_dataset(folder_path):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((32, 32)),  # Resize images to 32x32\n",
    "        transforms.ToTensor(),       # Convert images to tensors\n",
    "        transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1, 1]\n",
    "    ])\n",
    "    dataset = torchvision.datasets.ImageFolder(folder_path, transform=transform)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim=100):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 3 * 32 * 32),  # Output 3-channel image (RGB)\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        return img.view(-1, 3, 32, 32)  # Reshape to (batch, 3, 32, 32)\n",
    "\n",
    "\n",
    "# Define the Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(3 * 32 * 32, 512),  # Adjust input size to match flattened image size (3072)\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.size(0), -1)  # Flatten the image\n",
    "        return self.model(img_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to initialize weights\n",
    "def initialize_weights(model):\n",
    "    classname = model.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        nn.init.normal_(model.weight.data, mean=0.0, std=0.02)\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        nn.init.normal_(model.weight.data, mean=1.0, std=0.02)\n",
    "        nn.init.constant_(model.bias.data, 0)\n",
    "\n",
    "# Train the GAN\n",
    "def train_gan(dataloader, num_epochs=100, latent_dim=100, lr=0.002):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    generator = Generator(latent_dim).to(device)\n",
    "    discriminator = Discriminator().to(device)\n",
    "\n",
    "    # Apply weight initialization\n",
    "    generator.apply(initialize_weights)\n",
    "    discriminator.apply(initialize_weights)\n",
    "\n",
    "    loss_function = nn.BCELoss()\n",
    "    optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.00005, betas=(0.5, 0.999))\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (real_images, _) in enumerate(dataloader):\n",
    "            real_images = real_images.to(device)\n",
    "            batch_size = real_images.size(0)\n",
    "\n",
    "            # Real and fake labels\n",
    "            real_labels = torch.ones(batch_size, 1).to(device)\n",
    "            fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "            \n",
    "            optimizer_D.zero_grad()\n",
    "            outputs_real = discriminator(real_images)\n",
    "            loss_real = loss_function(outputs_real, real_labels)\n",
    "\n",
    "            z = torch.randn(batch_size, latent_dim).to(device)\n",
    "            fake_images = generator(z)\n",
    "            outputs_fake = discriminator(fake_images.detach())\n",
    "            loss_fake = loss_function(outputs_fake, fake_labels)\n",
    "\n",
    "            loss_D = loss_real + loss_fake\n",
    "            loss_D.backward()\n",
    "            optimizer_D.step()\n",
    "\n",
    "            for j in range(2):\n",
    "                optimizer_G.zero_grad()\n",
    "                z = torch.randn(batch_size, latent_dim).to(device)\n",
    "                fake_images = generator(z)\n",
    "\n",
    "                outputs = discriminator(fake_images)\n",
    "                loss_G = loss_function(outputs, real_labels)\n",
    "\n",
    "                retain_graph = (j == 0)\n",
    "                loss_G.backward(retain_graph=retain_graph)\n",
    "                optimizer_G.step()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] | Loss D: {loss_D.item():.4f} | Loss G: {loss_G.item():.4f}\")\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            vutils.save_image(fake_images, f\"generated_epoch_{epoch+1}.png\", normalize=True)\n",
    "\n",
    "    torch.save(generator.state_dict(), \"generator.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate New Images\n",
    "def generate_images(generator_path, num_images=5, latent_dim=100):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    generator = Generator(latent_dim).to(device)\n",
    "    generator.load_state_dict(torch.load(generator_path, map_location=device))\n",
    "    generator.eval()\n",
    "\n",
    "    z = torch.randn(num_images, latent_dim).to(device)\n",
    "    with torch.no_grad():\n",
    "        fake_images = generator(z)  # Shape: (num_images, channels, height, width)\n",
    "\n",
    "    for i, img in enumerate(fake_images):\n",
    "        img = img.cpu().numpy()  # Convert tensor to numpy\n",
    "        img = ((img + 1) / 2 * 255).astype(np.uint8)  # Normalize to [0, 255]\n",
    "\n",
    "        if img.shape[0] == 1:  # Grayscale Image (Shape: 1, H, W)\n",
    "            img = img.squeeze(0)  # Remove channel dimension\n",
    "            Image.fromarray(img, mode=\"L\").save(f\"generated_{i}.png\")\n",
    "        elif img.shape[0] == 3:  # RGB Image (Shape: 3, H, W)\n",
    "            img = np.transpose(img, (1, 2, 0))  # Convert from (C, H, W) -> (H, W, C)\n",
    "            Image.fromarray(img, mode=\"RGB\").save(f\"generated_{i}.png\")\n",
    "\n",
    "    print(f\"Generated {num_images} images and saved them.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100] | Loss D: 1.4266 | Loss G: 0.7201\n",
      "Epoch [2/100] | Loss D: 1.7262 | Loss G: 0.4325\n",
      "Epoch [3/100] | Loss D: 1.7003 | Loss G: 0.4858\n",
      "Epoch [4/100] | Loss D: 1.7342 | Loss G: 0.4646\n",
      "Epoch [5/100] | Loss D: 1.5375 | Loss G: 0.6278\n",
      "Epoch [6/100] | Loss D: 1.4734 | Loss G: 0.6464\n",
      "Epoch [7/100] | Loss D: 1.4303 | Loss G: 0.7099\n",
      "Epoch [8/100] | Loss D: 1.4677 | Loss G: 0.6934\n",
      "Epoch [9/100] | Loss D: 1.3264 | Loss G: 0.7511\n",
      "Epoch [10/100] | Loss D: 1.5875 | Loss G: 0.6860\n",
      "Epoch [11/100] | Loss D: 1.4282 | Loss G: 0.6949\n",
      "Epoch [12/100] | Loss D: 1.5668 | Loss G: 0.6434\n",
      "Epoch [13/100] | Loss D: 1.4925 | Loss G: 0.6388\n",
      "Epoch [14/100] | Loss D: 1.4785 | Loss G: 0.8118\n",
      "Epoch [15/100] | Loss D: 1.4137 | Loss G: 0.6992\n",
      "Epoch [16/100] | Loss D: 1.4166 | Loss G: 0.7258\n",
      "Epoch [17/100] | Loss D: 1.5295 | Loss G: 0.6772\n",
      "Epoch [18/100] | Loss D: 1.4050 | Loss G: 0.6997\n",
      "Epoch [19/100] | Loss D: 1.5533 | Loss G: 0.6522\n",
      "Epoch [20/100] | Loss D: 1.3906 | Loss G: 0.6782\n",
      "Epoch [21/100] | Loss D: 1.3857 | Loss G: 0.6698\n",
      "Epoch [22/100] | Loss D: 1.4067 | Loss G: 0.7046\n",
      "Epoch [23/100] | Loss D: 1.4324 | Loss G: 0.6816\n",
      "Epoch [24/100] | Loss D: 1.5215 | Loss G: 0.6042\n",
      "Epoch [25/100] | Loss D: 1.4081 | Loss G: 0.6858\n",
      "Epoch [26/100] | Loss D: 1.3907 | Loss G: 0.6978\n",
      "Epoch [27/100] | Loss D: 1.4190 | Loss G: 0.6948\n",
      "Epoch [28/100] | Loss D: 1.4005 | Loss G: 0.7166\n",
      "Epoch [29/100] | Loss D: 1.6542 | Loss G: 0.5734\n",
      "Epoch [30/100] | Loss D: 1.4130 | Loss G: 0.7046\n",
      "Epoch [31/100] | Loss D: 1.4396 | Loss G: 0.6946\n",
      "Epoch [32/100] | Loss D: 1.3306 | Loss G: 0.7055\n",
      "Epoch [33/100] | Loss D: 1.4841 | Loss G: 0.6717\n",
      "Epoch [34/100] | Loss D: 1.3500 | Loss G: 0.6859\n",
      "Epoch [35/100] | Loss D: 1.2896 | Loss G: 0.8628\n",
      "Epoch [36/100] | Loss D: 1.4369 | Loss G: 0.7061\n",
      "Epoch [37/100] | Loss D: 1.4418 | Loss G: 0.6279\n",
      "Epoch [38/100] | Loss D: 1.2836 | Loss G: 0.7010\n",
      "Epoch [39/100] | Loss D: 1.4193 | Loss G: 0.6929\n",
      "Epoch [40/100] | Loss D: 1.3546 | Loss G: 0.7523\n",
      "Epoch [41/100] | Loss D: 1.4149 | Loss G: 0.6898\n",
      "Epoch [42/100] | Loss D: 1.3554 | Loss G: 0.6952\n",
      "Epoch [43/100] | Loss D: 1.4422 | Loss G: 0.6576\n",
      "Epoch [44/100] | Loss D: 1.4213 | Loss G: 0.6568\n",
      "Epoch [45/100] | Loss D: 1.4738 | Loss G: 0.6578\n",
      "Epoch [46/100] | Loss D: 1.3403 | Loss G: 0.7059\n",
      "Epoch [47/100] | Loss D: 1.4448 | Loss G: 0.6937\n",
      "Epoch [48/100] | Loss D: 1.4817 | Loss G: 0.6775\n",
      "Epoch [49/100] | Loss D: 1.4198 | Loss G: 0.7291\n",
      "Epoch [50/100] | Loss D: 1.4033 | Loss G: 0.7044\n",
      "Epoch [51/100] | Loss D: 1.3574 | Loss G: 0.6968\n",
      "Epoch [52/100] | Loss D: 1.4076 | Loss G: 0.6937\n",
      "Epoch [53/100] | Loss D: 1.4162 | Loss G: 0.7124\n",
      "Epoch [54/100] | Loss D: 1.4324 | Loss G: 0.7038\n",
      "Epoch [55/100] | Loss D: 1.4237 | Loss G: 0.6950\n",
      "Epoch [56/100] | Loss D: 1.4288 | Loss G: 0.6995\n",
      "Epoch [57/100] | Loss D: 1.4056 | Loss G: 0.6948\n",
      "Epoch [58/100] | Loss D: 1.4020 | Loss G: 0.7009\n",
      "Epoch [59/100] | Loss D: 1.3907 | Loss G: 0.7076\n",
      "Epoch [60/100] | Loss D: 1.3981 | Loss G: 0.7145\n",
      "Epoch [61/100] | Loss D: 1.4244 | Loss G: 0.6683\n",
      "Epoch [62/100] | Loss D: 1.3804 | Loss G: 0.6915\n",
      "Epoch [63/100] | Loss D: 1.3872 | Loss G: 0.7331\n",
      "Epoch [64/100] | Loss D: 1.3378 | Loss G: 0.7590\n",
      "Epoch [65/100] | Loss D: 1.3830 | Loss G: 0.6987\n",
      "Epoch [66/100] | Loss D: 1.4035 | Loss G: 0.6715\n",
      "Epoch [67/100] | Loss D: 1.4062 | Loss G: 0.6706\n",
      "Epoch [68/100] | Loss D: 1.3996 | Loss G: 0.7008\n",
      "Epoch [69/100] | Loss D: 1.4097 | Loss G: 0.6609\n",
      "Epoch [70/100] | Loss D: 1.3963 | Loss G: 0.7010\n",
      "Epoch [71/100] | Loss D: 1.5217 | Loss G: 0.6507\n",
      "Epoch [72/100] | Loss D: 1.3283 | Loss G: 0.7031\n",
      "Epoch [73/100] | Loss D: 1.3818 | Loss G: 0.7037\n",
      "Epoch [74/100] | Loss D: 1.3461 | Loss G: 0.7011\n",
      "Epoch [75/100] | Loss D: 1.4167 | Loss G: 0.7055\n",
      "Epoch [76/100] | Loss D: 1.3948 | Loss G: 0.7080\n",
      "Epoch [77/100] | Loss D: 1.4566 | Loss G: 0.7092\n",
      "Epoch [78/100] | Loss D: 1.4289 | Loss G: 0.6537\n",
      "Epoch [79/100] | Loss D: 1.3311 | Loss G: 0.7084\n",
      "Epoch [80/100] | Loss D: 1.4924 | Loss G: 0.6261\n",
      "Epoch [81/100] | Loss D: 1.4350 | Loss G: 0.7090\n",
      "Epoch [82/100] | Loss D: 1.3832 | Loss G: 0.7460\n",
      "Epoch [83/100] | Loss D: 1.3938 | Loss G: 0.7009\n",
      "Epoch [84/100] | Loss D: 1.3947 | Loss G: 0.6808\n",
      "Epoch [85/100] | Loss D: 1.3866 | Loss G: 0.7070\n",
      "Epoch [86/100] | Loss D: 1.4232 | Loss G: 0.6841\n",
      "Epoch [87/100] | Loss D: 1.4214 | Loss G: 0.6993\n",
      "Epoch [88/100] | Loss D: 1.4531 | Loss G: 0.7087\n",
      "Epoch [89/100] | Loss D: 1.3831 | Loss G: 0.6774\n",
      "Epoch [90/100] | Loss D: 1.4244 | Loss G: 0.7072\n",
      "Epoch [91/100] | Loss D: 1.3990 | Loss G: 0.7070\n",
      "Epoch [92/100] | Loss D: 1.4434 | Loss G: 0.6220\n",
      "Epoch [93/100] | Loss D: 1.4026 | Loss G: 0.7026\n",
      "Epoch [94/100] | Loss D: 1.4010 | Loss G: 0.6822\n",
      "Epoch [95/100] | Loss D: 1.4119 | Loss G: 0.6910\n",
      "Epoch [96/100] | Loss D: 1.3958 | Loss G: 0.6877\n",
      "Epoch [97/100] | Loss D: 1.3537 | Loss G: 0.6941\n",
      "Epoch [98/100] | Loss D: 1.4528 | Loss G: 0.6562\n",
      "Epoch [99/100] | Loss D: 1.3659 | Loss G: 0.7092\n",
      "Epoch [100/100] | Loss D: 1.4388 | Loss G: 0.6980\n"
     ]
    }
   ],
   "source": [
    "folder_path = r\"D:\\college\\imp-doc\\sem6\\GENAI\\project\\new\"\n",
    "dataloader = load_dataset(folder_path)\n",
    "train_gan(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 5 images and saved them.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sameer\\AppData\\Local\\Temp\\ipykernel_33180\\1683722680.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  generator.load_state_dict(torch.load(generator_path, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "generate_images(\"generator.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved as 'generated_image1.png'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "# Generate a batch of images\n",
    "latent_dim = 100\n",
    "generator = Generator(latent_dim)  # Ensure the generator is loaded\n",
    "z = torch.randn(1, latent_dim)  # Generate a random noise vector\n",
    "generated_img = generator(z)\n",
    "\n",
    "# Save the image\n",
    "vutils.save_image(generated_img, \"generated_image1.png\", normalize=True)\n",
    "print(\"Image saved as 'generated_image1.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.1-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.1-cp312-cp312-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.57.0-cp312-cp312-win_amd64.whl.metadata (104 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp312-cp312-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\sameer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sameer\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\sameer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (11.0.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sameer\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sameer\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.1-cp312-cp312-win_amd64.whl (8.1 MB)\n",
      "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 2.9/8.1 MB 15.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 6.3/8.1 MB 16.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.1/8.1 MB 16.1 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.3.1-cp312-cp312-win_amd64.whl (220 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.57.0-cp312-cp312-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.2/2.2 MB 13.8 MB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.8-cp312-cp312-win_amd64.whl (71 kB)\n",
      "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.57.0 kiwisolver-1.4.8 matplotlib-3.10.1 pyparsing-3.2.3\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'generator_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[112]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Assuming you have stored loss values in lists\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m epochs = \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[43mgenerator_loss\u001b[49m) + \u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# Adjust based on stored losses\u001b[39;00m\n\u001b[32m      7\u001b[39m plt.figure(figsize=(\u001b[32m10\u001b[39m, \u001b[32m5\u001b[39m))\n\u001b[32m      8\u001b[39m plt.plot(epochs, generator_loss, label=\u001b[33m\"\u001b[39m\u001b[33mGenerator Loss (G)\u001b[39m\u001b[33m\"\u001b[39m, color=\u001b[33m\"\u001b[39m\u001b[33mblue\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'generator_loss' is not defined"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have stored loss values in lists\n",
    "epochs = range(1, len(loss_G) + 1)  # Adjust based on stored losses\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, generator_loss, label=\"Generator Loss (G)\", color=\"blue\")\n",
    "plt.plot(epochs, discriminator_loss, label=\"Discriminator Loss (D)\", color=\"red\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Generator & Discriminator Loss Over Time\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
